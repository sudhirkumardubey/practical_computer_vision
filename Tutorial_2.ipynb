{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Reading from video file and camera\n",
    "• Simple Color Detection and Tracking\n",
    "• Point Operator\n",
    "• Adjusting Contrast and Brightness\n",
    "• Array Slicing with NumPy\n",
    "• Image Blending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPS:  29.9788285109386 FPS\n",
      "Frame Count:  354.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qt.qpa.plugin: Could not find the Qt platform plugin \"wayland\" in \"/home/sudhir/.local/lib/python3.10/site-packages/cv2/qt/plugins\"\n"
     ]
    }
   ],
   "source": [
    "# cv2.waitKey(0) for displaying image, and cv2.waitKey(1) for displaying video\n",
    "\n",
    "# create a video capture object from a file\n",
    "video = cv2.VideoCapture('Video/City.mp4')\n",
    "\n",
    "if video.isOpened() == False:\n",
    "    print('Error opening video stream or file')\n",
    "else:\n",
    "    fps = video.get(cv2.CAP_PROP_FPS) # frame rate info\n",
    "    print('FPS: ', fps, 'FPS')\n",
    "    frame_Count = video.get(cv2.CAP_PROP_FRAME_COUNT) # get frame count\n",
    "    print('Frame Count: ', frame_Count)\n",
    "\n",
    "    cv2.namedWindow(\"Frame\")\n",
    "    cv2.setWindowProperty(\"Frame\",cv2.WND_PROP_TOPMOST, 1)\n",
    "\n",
    "    while video.isOpened():\n",
    "        ret, frame = video.read() # capture next frame\n",
    "        if ret == True:\n",
    "            cv2.imshow(\"Frame\", frame)\n",
    "            time.sleep(1/fps) # adjust frame rate\n",
    "            if cv2.waitKey(10000) & 0xFF == ord('x'): # wait to press ESC\n",
    "                break\n",
    "            else:\n",
    "                break # no next frame\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera is Open\n",
      "Camera is closed\n"
     ]
    }
   ],
   "source": [
    "# create video capture from a camera\n",
    "\n",
    "cam = cv2.VideoCapture(0) # get camera device\n",
    "if cam.isOpened() == True:\n",
    "\n",
    "    print(\"Camera is Open\")\n",
    "\n",
    "    cv2.namedWindow(\"Camera\")\n",
    "    cv2.setWindowProperty(\"Camera\", cv2.WND_PROP_TOPMOST, 1)\n",
    "\n",
    "    while cam.isOpened():\n",
    "        ret, frame = cam.read() # capture the next frame\n",
    "\n",
    "        if ret == True:\n",
    "            cv2.imshow(\"Camera\", frame) # show the frame\n",
    "            if cv2.waitKey(50000) == ord('x'):\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"Camera is closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4)\n",
      "(140, 1, 2)\n",
      "43 6 144 72\n"
     ]
    }
   ],
   "source": [
    "# color detection in Image\n",
    "\n",
    "rgb = cv2.imread('Video/rgb.jpg')\n",
    "hsv = cv2.cvtColor(rgb, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# define range of color\n",
    "lower_red = np.array([0, 200, 20]) # min h, s, v\n",
    "upper_red = np.array([10, 255, 255]) # max h, s, v\n",
    "\n",
    "# create mask for red color\n",
    "red_mask = cv2.inRange(hsv, lower_red, upper_red)\n",
    "\n",
    "# contour in mask\n",
    "contours, hierarchy = cv2.findContours(red_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "\"\"\"contours: It is a Python list that contains all the detected contours. \n",
    "Each contour is represented as a numpy array of shape (n, 1, 2),\n",
    "where n is the number of points on the contour. Each point contains the (x, y) coordinates of the contour.\"\"\"\n",
    "\n",
    "'''\n",
    "hierarchy: It is a representation of the hierarchical relationships between contours. \n",
    "It provides information about the topology of the contours, such as which contours are nested or have holes.\n",
    " The hierarchy is represented as a numpy array of shape (1, N, 4), where N is the total number of contours. \n",
    " Each contour's hierarchy is defined by four values: [Next, Previous, First Child, Parent].\n",
    "\n",
    "Next: It represents the index of the next contour at the same hierarchical level. If there is no next contour, the value is -1.\n",
    "\n",
    "Previous: It represents the index of the previous contour at the same hierarchical level. If there is no previous contour, the value is -1.\n",
    "\n",
    "First Child: It represents the index of the first child contour. If there is no child contour, the value is -1.\n",
    "\n",
    "Parent: It represents the index of the parent contour. If there is no parent contour, the value is -1.\n",
    "'''\n",
    "\n",
    "\n",
    "# create output image and draw contour in green\n",
    "output1 = rgb.copy()\n",
    "cv2.drawContours(output1, contours, -1, (0,255,0), 3) # image, list of contours, parameter indicating all contour\n",
    "                                                        #to be drawn, color of contour, thickness is 3 pixel\n",
    "\n",
    "# create output image and draw bounding box in rectangle\n",
    "output2 = rgb.copy()\n",
    "\n",
    "for cnt in contours:\n",
    "    x,y,w,h = cv2.boundingRect(cnt)\n",
    "\n",
    "print(hierarchy[0].shape)\n",
    "print(contours[0].shape)\n",
    "print(x, y, w, h)\n",
    "\n",
    "cv2.rectangle(output2, (x,y), (x+w, y+h), (0,255,0), 2)\n",
    "\n",
    "# show the images\n",
    "# cv2.imshow(\"input\", rgb)\n",
    "# cv2.imshow(\"mask\", red_mask)\n",
    "# cv2.imshow(\"output1\", output1)\n",
    "# cv2.imshow(\"output2\", output2)\n",
    "\n",
    "# cv2.setWindowProperty(\"input\", cv2.WND_PROP_TOPMOST, 1)\n",
    "# cv2.setWindowProperty(\"mask\", cv2.WND_PROP_TOPMOST, 1)\n",
    "# cv2.setWindowProperty(\"output1\", cv2.WND_PROP_TOPMOST, 1)\n",
    "# cv2.setWindowProperty(\"output2\", cv2.WND_PROP_TOPMOST, 1)\n",
    "\n",
    "\n",
    "cv2.waitKey(0) # waiting for a key pressed\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qt.qpa.plugin: Could not find the Qt platform plugin \"wayland\" in \"/home/sudhir/.local/lib/python3.10/site-packages/cv2/qt/plugins\"\n"
     ]
    }
   ],
   "source": [
    "# color tracking in the video\n",
    "\n",
    "video = cv2.VideoCapture('Video/City.mp4')\n",
    "\n",
    "if video.isOpened() == False:\n",
    "    print('Error opening video')\n",
    "else:\n",
    "    fps = video.get(cv2.CAP_PROP_FPS) # or set fps = 30\n",
    "    size = (int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "            , int(video.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "    # print(size)\n",
    "    cv2.namedWindow('frame')\n",
    "    cv2.namedWindow('mask')\n",
    "    cv2.setWindowProperty('frame', cv2.WND_PROP_TOPMOST, 1)\n",
    "    cv2.setWindowProperty('mask', cv2.WND_PROP_TOPMOST, 1)\n",
    "\n",
    "    while video.isOpened():\n",
    "        ret, frame = video.read()\n",
    "        if ret == True:\n",
    "            hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "            # define the range of \"red\" color\n",
    "            # OpenCV HSV scale:\n",
    "            # H (hue): 0-180\n",
    "            # S (saturation): 0-255 (0=gray, 255=pure color)\n",
    "            # V (brightness): 0-255 (0=no brightness, 255=full brightness )\n",
    "\n",
    "            # mask red color\n",
    "            red_min = np.array([165, 170, 20])\n",
    "            red_max = np.array([180, 255, 255])\n",
    "\n",
    "            # mask blue color\n",
    "            # red_min = np.array([90, 50, 50])\n",
    "            # red_max = np.array([130, 255, 255])\n",
    "\n",
    "            # # mask green color\n",
    "            # red_min = np.array([40, 50, 50])  # Lower bounds of green color in HSV\n",
    "            # red_max = np.array([80, 255, 255])  # Upper bounds of green color in HSV\n",
    "\n",
    "            mask = cv2.inRange(hsv, red_min, red_max)\n",
    "\n",
    "            # remove small blobs in the mask by morphological operations\n",
    "            mask = cv2.erode(mask, None, iterations=2)\n",
    "            mask = cv2.dilate(mask, None, iterations=2)\n",
    "\n",
    "            # find contour in mask\n",
    "            contours, hierarchy = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "            for cnt in contours:\n",
    "                x,y,w,h = cv2.boundingRect(cnt)\n",
    "                cv2.rectangle(frame, (x,y), (x+w, y+h), (0,255,0), 3)\n",
    "            \n",
    "            cv2.imshow(\"frame\", frame) # shows current frame\n",
    "            cv2.imshow(\"mask\", mask) # shows current frame \n",
    "\n",
    "            time.sleep(1/fps)\n",
    "\n",
    "            if cv2.waitKey(1)  & 0xFF == ord('x'):\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO check hsv color  and color tracking in an image\n",
    "\n",
    "image = cv2.imread(\"Video/pier.jpg\")\n",
    "hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "cv2.imshow(\"HSV Image\", hsv_image)\n",
    "\n",
    "# Define the color range\n",
    "red_min = np.array([15,50,180])\n",
    "red_max = np.array([40,255,255])\n",
    "\n",
    "# Create a mask for the red color\n",
    "mask = cv2.inRange(hsv, red_min, red_max)\n",
    "\n",
    "# Find contours in the mask\n",
    "contours, hierarchy = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Draw rectangles around the detected contours\n",
    "for cnt in contours:\n",
    "    x,y,w,h = cv2.boundingRect(cnt)\n",
    "    cv2.rectangle(image, (x,y), (x+w, y+h), (0,255,0), 3)# smilarly we can do circle mask etc\n",
    "\n",
    "# Display the original image and the mask\n",
    "cv2.imshow(\"Original Image\", image)\n",
    "cv2.imshow(\"Mask\", mask)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# color tracking using Cam of Laptop with HSV\n",
    "\n",
    "# get camera device\n",
    "cameraCapture = cv2.VideoCapture(0)\n",
    "\n",
    "# capture the first frame:\n",
    "success, frame = cameraCapture.read()\n",
    "\n",
    "# loops untill there is no more frame\n",
    "while success:\n",
    "    success, frame = cameraCapture.read() # to get next frame\n",
    "\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    red_min = np.array([165, 150, 50])\n",
    "    red_max = np.array([180, 255, 255])\n",
    "\n",
    "    red_mask = cv2.inRange(hsv, red_min, red_max)\n",
    "\n",
    "    red_mask = cv2.erode(red_mask, None, iterations=3)\n",
    "    red_mask = cv2.dilate(red_mask, None, iterations=5)\n",
    "\n",
    "    contours, hierarchy = cv2.findContours(red_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    for cnt in contours:\n",
    "        x,y,w,h = cv2.boundingRect(cnt)\n",
    "        cv2.rectangle(frame, (x,y), (x+w, y+h), (0,255,0), 2)\n",
    "\n",
    "    cv2.imshow(\"Camera\", frame)\n",
    "    cv2.imshow(\"mask\", red_mask)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('x'):\n",
    "        break\n",
    "\n",
    "cameraCapture.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constrast brightness : Slow implementation (brute force)\n",
    "\n",
    "'''\n",
    "# Point operators:\n",
    "Basic Linear Function: g(x) = alpha x f(x) + beta --> g(i,j) = alpha x f(i.j) + beta\n",
    "alpha --> gain --> contrast\n",
    "beta --> bias --> brightness\n",
    "\n",
    "g(x) = (1-alpha) x f0(x) + alpha x f1(x)\n",
    "dst = alpha x src1 + beta x src2 + gamma\n",
    "'''\n",
    "\n",
    "def constrastBrightnessSlow(input,  output, alpha, beta):\n",
    "    # Uisng loop\n",
    "    for y in range (input.shape[0]): # height\n",
    "        for x in range (input.shape[1]): # width\n",
    "            if (len(input.shape)==2):\n",
    "                output[y,x] = np.clip(alpha*input[y,x] + beta, 0, 255)\n",
    "            if (len(input.shape)==3):\n",
    "                output[y,x,:] = np.clip(alpha*input[y,x,:] + beta, 0, 255)\n",
    "\n",
    "# read image\n",
    "input = cv2.imread(\"Video/pier.jpg\", 0)\n",
    "\n",
    "# initialize alpha (contrast) and beta (brightness)\n",
    "alpha = 2.0\n",
    "beta = 40\n",
    "\n",
    "# create output matrix and initial pixel value equal to zero , with same size and type of original image\n",
    "output = np.zeros(input.shape, input.dtype)\n",
    "\n",
    "constrastBrightnessSlow(input, output, alpha, beta)\n",
    "\n",
    "# create window and show image\n",
    "cv2.namedWindow('Contrast and brigthness', 1)\n",
    "cv2.imshow(\"Contrast and Brightness\", output)\n",
    "\n",
    "cv2.waitKey(0) # waiting for a key pressed\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimized code:\n",
    "\n",
    "def contrastBrigtness(input, output, alpha, beta):\n",
    "    # using numpy slicing\n",
    "    if (len(input.shape)==2):\n",
    "        height, width = input.shape\n",
    "        print(height, width)\n",
    "        output[0:height, 0:width] = np.clip(alpha * input[0:height,0:width]+beta, 0, 255)\n",
    "\n",
    "    if (len(input.shape)==3):\n",
    "        height, width, channel = input.shape\n",
    "        output[:height, :width, :channel] = np.clip(alpha*input[:height, :width, :channel]+beta, 0, 255)\n",
    "    \n",
    "input = cv2.imread('Video/pier.jpg')\n",
    "input[:,:,1] = 0\n",
    "my_roi = input[0:100, 0:100]\n",
    "input[300:400, 300:400] = my_roi\n",
    "\n",
    "cv2.namedWindow('Constract and brighness', 1)\n",
    "\n",
    "alpha = 1.0\n",
    "beta = 0.0\n",
    "\n",
    "while(True):\n",
    "\n",
    "    output = np.zeros(input.shape, input.dtype)\n",
    "\n",
    "    contrastBrigtness(input, output, alpha, beta)\n",
    "\n",
    "    # put text into the input image\n",
    "    cv2.putText(output, 'aplha: '+ str(format(alpha, '.1f')) + 'beta: '+str(format(beta, '.2f')), (25, 40), cv2.FONT_HERSHEY_PLAIN, 2.0, (255, 255, 255), 2)\n",
    "    cv2.putText(output, '[ESC] quit', (output.shape[1]-120, 30), cv2.FONT_HERSHEY_PLAIN, 1.0, (255, 255, 255), 1)\n",
    "\n",
    "    cv2.imshow('constrast and brightness', output)\n",
    "\n",
    "    # handle keyboard event\n",
    "    key = cv2.waitKey(20) # wait 10 ms and get keyboard event\n",
    "\n",
    "    if key == 119: # w : increase contrast\n",
    "        if(alpha < 3.0):\n",
    "            alpha += 0.1\n",
    "    elif key == 121 : # y : decrease contrast\n",
    "        if(alpha > 0.2):\n",
    "            alpha -= 0.1\n",
    "    elif key == 115: # s : increase brightness\n",
    "        if(beta < 100):\n",
    "            beta += 1\n",
    "    elif key == 97: # a\n",
    "        if(beta > 0):\n",
    "            beta -= 1\n",
    "    elif key == 27: # Esc\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using addweighted function to change brightness and contrast\n",
    "\n",
    "\n",
    "input = cv2.imread('Video/pier.jpg', 1)\n",
    "\n",
    "cv2.namedWindow('Contrast and brightness', 1)\n",
    "\n",
    "alpha = 1.0\n",
    "beta = 0.0\n",
    "\n",
    "while True:\n",
    "    output = np.zeros(input.shape, input.dtype)\n",
    "    output = cv2.addWeighted(input, alpha, input, 0, beta, output)\n",
    "\n",
    "    # put text\n",
    "    cv2.putText(output, 'alpha: '+ str(format(alpha, '.1f'))+ \" beta : \"+ str(format(beta, '.1f')), (25, 40), cv2.FONT_HERSHEY_COMPLEX_SMALL, 2.0, (255, 255, 2555), 2)\n",
    "    cv2.putText(output, '[ESC] : quit', (output.shape[1]-120, 30), cv2.FONT_HERSHEY_PLAIN, 1.0, (255, 255, 255), 1)\n",
    "\n",
    "    cv2.imshow('contrast and brightness', output)\n",
    "\n",
    "    key = cv2.waitKey(10)\n",
    "    if key == 119: # w => increase contrast\n",
    "        if(alpha < 3.0): \n",
    "            alpha += 0.1\n",
    "    elif  key == 121: # y => decrease contrast\n",
    "        if(alpha > 0.2): \n",
    "            alpha -= 0.1\n",
    "    elif  key == 115: # s => increase brightness\n",
    "        if(beta < 100): \n",
    "            beta += 1\n",
    "    elif  key == 97: # a => decrease brightness\n",
    "        if(beta > 0): \n",
    "            beta -= 1\n",
    "    elif  key == 27: # ESC => break the loop\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image blending\n",
    "\n",
    "# read image\n",
    "img1 = cv2.imread('Video/pier.jpg', 1)\n",
    "img2 = cv2.imread('Video/beach.jpg', 1)\n",
    "\n",
    "# create window\n",
    "cv2.namedWindow('Image blending', 1)\n",
    "\n",
    "# initialize alpha(contract)\n",
    "alpha = 0.0\n",
    "\n",
    "while True:\n",
    "\n",
    "    # create output matrix and initialize pixel values\n",
    "    output = np.zeros(input.shape, input.dtype)\n",
    "\n",
    "    # initialize beta(brightness)\n",
    "    beta = 1.0 - alpha\n",
    "\n",
    "    # Use addWeighted function to adjust contrast and brightness\n",
    "    cv2.addWeighted(img1, alpha, img2, beta, 0, output)\n",
    "\n",
    "    # put text into the image\n",
    "    cv2.putText(output, \"alpha: \"+str(format(alpha, '.1f')), (25, 40), cv2.FONT_HERSHEY_PLAIN, 2.0, (255,255,255), 2)\n",
    "    cv2.putText(output, \"[ESC] quit\", (output.shape[1]-120, 30), cv2.FONT_HERSHEY_PLAIN, 1.0, (255,255,255), 1)\n",
    "\n",
    "    # show image\n",
    "    cv2.imshow('Image blend', output)\n",
    "\n",
    "    # handle keyboard event\n",
    "    key = cv2.waitKey(20)\n",
    "\n",
    "    if key == 115 : #s: increase alpha\n",
    "        if (alpha < 0.9):\n",
    "            alpha += 0.1\n",
    "    elif key == 97: # a : decrease alpha\n",
    "        if (alpha > 0.1):\n",
    "            alpha -= 0.1\n",
    "    elif key == 27: # [ESC] quit\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of passing argument \n",
    "\n",
    "# Create an ArgumentParser object\n",
    "# parser = argparse.ArgumentParser(description='My Command-Line Program')\n",
    "\n",
    "# # Add arguments\n",
    "# parser.add_argument('input_file', help='Path to the input file')\n",
    "# parser.add_argument('-o', '--output', help='Path to the output file')\n",
    "\n",
    "# # Parse the command-line arguments\n",
    "# args = parser.parse_args()\n",
    "\n",
    "# # Access the values of the arguments\n",
    "# input_file = args.input_file\n",
    "# output_file = args.output\n",
    "\n",
    "# # Use the values in your program\n",
    "# print(\"Input file:\", input_file)\n",
    "# print(\"Output file:\", output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
