{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "• Geometric Image Transformation\n",
    "• Affine Transformation\n",
    "• Perspective Transformation\n",
    "• Image Alignment\n",
    "• Object Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image\n",
    "img = cv2.imread('Image/house.jpg')\n",
    "\n",
    "h, w = img.shape[:2]\n",
    "tx, ty = w/2, h/2\n",
    "angle = np.radians(45)\n",
    "scale = 0.8\n",
    "\n",
    "# define rotation matrix\n",
    "R = np.array([\n",
    "    [np.cos(angle), np.sin(angle), 0],\n",
    "    [-np.sin(angle), np.cos(angle), 0],\n",
    "    [0,0,1]\n",
    "])\n",
    "# define translation matrix\n",
    "T = np.array([\n",
    "    [1, 0, tx],\n",
    "    [0, 1, ty],\n",
    "    [0, 0, 1]\n",
    "])\n",
    "# define scale matrix\n",
    "S = np.array([\n",
    "    [scale, 0, 0],\n",
    "    [0, scale, 0],\n",
    "    [0, 0, 1]\n",
    "])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(640, 480)\n",
      "(2, 640, 480)\n",
      "(2, 307200)\n",
      "(3, 307200)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23256/1055770235.py:23: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  coords = coords.astype(np.int)\n",
      "/tmp/ipykernel_23256/1055770235.py:32: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  warp_coords = np.round(np.linalg.inv(A)@coords).astype(np.int)\n"
     ]
    }
   ],
   "source": [
    "'''Rotation and scaling usually requires prior translation of\n",
    "the image center to the origin of the coordinate system\n",
    "and then back again by inverse translation'''\n",
    "\n",
    "# compute transformation matrix by multiplying the single transformations\n",
    "A = T @ R @ S @ np.linalg.inv(T)\n",
    "# print(A)\n",
    "\n",
    "# define grid to represent image coordinate using np.indices\n",
    "dim = (w, h)\n",
    "print(dim)\n",
    "\n",
    "coords1 = np.indices(dim) # resulted shape: (2 (x,y), width, height)\n",
    "print(coords1.shape)\n",
    "coords = np.indices(dim).reshape(2,-1) # resulted shape: (2,row*column)\n",
    "print(coords.shape)\n",
    "\n",
    "# homogeneous coordinates by adding a row with ones after last row\n",
    "coords = np.vstack((coords, np.ones(coords.shape[1])))# resulted shape: (3,row*column)\n",
    "print(coords.shape)\n",
    "\n",
    "# get indices of columns (coords[0]) and rows (coords[1])\n",
    "coords = coords.astype(np.int)\n",
    "xcoord, ycoord = coords[0], coords[1]\n",
    "\n",
    "# apply transformation matrix A\n",
    "warp_coords = np.round(A@coords).astype(np.int64)\n",
    "xcoord2, ycoord2  = warp_coords[0,:], warp_coords[1,:]\n",
    "xcoord, ycoord = coords[0], coords[1] \n",
    "\n",
    "# !!! to avoid aliasing and gaps => apply the inverse of A\n",
    "# warp_coords = np.round(np.linalg.inv(A)@coords).astype(np.int)\n",
    "# xcoord2, ycoord2 = warp_coords[0,:], warp_coords[1,:]\n",
    "\n",
    "# get indices only within image boundary\n",
    "indices = np.where((xcoord2 >= 0) & (xcoord2 < w) & (ycoord2 >= 0) & (ycoord2 < h))\n",
    "\n",
    "# get pixels within image boundary\n",
    "xpix2, ypix2 = xcoord2[indices], ycoord2[indices]\n",
    "xpix, ypix = xcoord[indices], ycoord[indices]\n",
    "\n",
    "\n",
    "# !!! swap targets of coordinates when apply inverse of A\n",
    "# xpix2, ypix2 = xcoord[indices], ycoord[indices]\n",
    "# xpix, ypix = xcoord2[indices], ycoord2[indices]\n",
    "\n",
    "\n",
    "# map the pixel values to new location in output array\n",
    "output = np.zeros(img.shape, img.dtype)\n",
    "output[ypix2, xpix2] = img[ypix, xpix]\n",
    "\n",
    "# show images\n",
    "# cv2.imshow(\"input\", img)\n",
    "cv2.imshow(\"output\", output)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affine transformation\n",
    "\n",
    "# load image\n",
    "img = cv2.imread('Image/house.jpg')\n",
    "height, width = img.shape[:2]\n",
    "tx, ty = width/2, height/2\n",
    "angle = np.radians(45)\n",
    "scale = 1.25\n",
    "\n",
    "# composite transformtaion matrix\n",
    "sin_theta = np.sin(angle)\n",
    "cos_theta = np.cos(angle)\n",
    "\n",
    "a_11 = scale * cos_theta\n",
    "a_21 = -scale * sin_theta\n",
    "a_12 = scale * sin_theta\n",
    "a_22 = scale * cos_theta\n",
    "a_13 = tx * (1 - scale * cos_theta) - scale * sin_theta * ty\n",
    "a_23 = ty * (1 - scale * cos_theta) + scale * sin_theta * tx\n",
    "# A = np.array([[a_11, a_12, a_13],[a_21, a_22, a_23]])\n",
    "\n",
    "# alternative: get transformation matrix by OpenCV\n",
    "A = cv2.getRotationMatrix2D((tx, ty), np.rad2deg(angle), scale)\n",
    "\n",
    "# transform image by OpenCV function cv2.warpAffine\n",
    "output = cv2.warpAffine(img, A, (width, height))\n",
    "\n",
    "\n",
    "# show images\n",
    "cv2.imshow(\"input\", img)\n",
    "cv2.imshow(\"output\", output)\n",
    "\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image alignment\n",
    "\n",
    "img1 = cv2.imread('Image/book1.jpg')\n",
    "img2 = cv2.imread('Image/book2.jpg')\n",
    "\n",
    "# find the keypoints and descriptors using ORB\n",
    "orb = cv2.ORB_create(nfeatures=2000)\n",
    "kp1, dsc1 = orb.detectAndCompute(img1, None)\n",
    "kp2, dsc2 = orb.detectAndCompute(img2, None)\n",
    "\n",
    "# get matches on the two images\n",
    "bf = cv2.BFMatcher_create(cv2.NORM_HAMMING)\n",
    "matches = bf.match(dsc1, dsc2)\n",
    "\n",
    "# sort matches in the order of their distance\n",
    "matches = sorted(matches, key=lambda x:x.distance)\n",
    "good = matches[:30] # we need at least 4 matches to estimate homography\n",
    "\n",
    "# draw matches\n",
    "img_matches = cv2.drawMatches(img1,kp1,img2,kp2,good,None,matchColor=(0,255,0),singlePointColor=(255, 0, 255))\n",
    "\n",
    "# we need at least four matches to find homography between the images\n",
    "\n",
    "if len(good)> 4:\n",
    "\n",
    "    # extract location (keypoints) of good matches\n",
    "    p1, p2 = [], []\n",
    "    for i, match in enumerate(good):\n",
    "        p1.append([kp1[match.queryIdx].pt])\n",
    "        p2.append([kp2[match.trainIdx].pt])\n",
    "    \n",
    "    p1 = np.asarray(p1)\n",
    "    p2 = np.asarray(p2)\n",
    "\n",
    "    # find homography using RANSAC: it removes outliers (incorrect matches)\n",
    "    H, status = cv2.findHomography(p2, p1, cv2.RANSAC)\n",
    "\n",
    "    # Apply homography to warp perspective of the image to be aligned\n",
    "    h, w = img1.shape[:2]\n",
    "    output = cv2.warpPerspective(img2, H, (w, h))\n",
    "\n",
    "    # Show images\n",
    "    cv2.imshow(\"img1 (template)\", img1)\n",
    "    cv2.imshow(\"img2\", img2)\n",
    "    cv2.imshow(\"matches\", img_matches)\n",
    "    cv2.imshow(\"aligned image\", output)\n",
    "\n",
    "else:\n",
    "    print(\"Error, not enough matches\\n\")\n",
    "\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object recognition\n",
    "\n",
    "img1 = cv2.imread('Image/object.jpg')\n",
    "img2 = cv2.imread('Image/objectScene.jpg')\n",
    "\n",
    "# find the keypoints and descriptors using ORB\n",
    "orb = cv2.ORB_create()\n",
    "kp1, descriptors_1 = orb.detectAndCompute(img1, None)\n",
    "kp2, descriptors_2 = orb.detectAndCompute(img2, None)\n",
    "\n",
    "\n",
    "# get matches on the two images\n",
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "bf_matches = bf.match(descriptors_1, descriptors_2)\n",
    "\n",
    "# sort matches in the order of their distance\n",
    "bf_matches = sorted(bf_matches, key=lambda x: x.distance)\n",
    "good = bf_matches[:30]\n",
    "\n",
    "# draw matches\n",
    "# img_matches = cv2.drawMatches(img1, kp1, img2, kp2, good, None, matchColor=(255, 255, 0), singlePointColor=(255, 0, 255))\n",
    "\n",
    "# we need at least four matches to find homography between the images\n",
    "if len(good) > 4:\n",
    "\n",
    "    # extract location (keypoints) of good matches\n",
    "    p1, p2 = [], []\n",
    "    for i, match in enumerate(good):\n",
    "        p1.append([kp1[match.queryIdx].pt])\n",
    "        p2.append([kp2[match.trainIdx].pt])\n",
    "    p1 = np.asarray(p1)\n",
    "    p2 = np.asarray(p2)\n",
    "\n",
    "    # find homography using RANSAC\n",
    "    H, status = cv2.findHomography(p1, p2, cv2.RANSAC, 5.0)\n",
    "\n",
    "    # Determine the four corner coordinates corners_src of the reference image\n",
    "    # get the corner coordinates of the first image\n",
    "    height, width = img1.shape[:2]\n",
    "    corners_src = np.float32([[0, 0], [0, height-1], [width-1, height-1], [width-1, 0]]).reshape(-1, 1, 2)\n",
    "\n",
    "    # the 'detected' object in the 'scene' image: (Apply homography to perspective transform corner coordinates corners_src)\n",
    "    corners_dst = cv2.perspectiveTransform(corners_src, H)\n",
    "\n",
    "    # draw corners of the detected object\n",
    "    output = img2.copy()\n",
    "    cv2.polylines(output, [np.int32(corners_dst)], True, (0, 255, 255), 10)\n",
    "\n",
    "    # print estimated homography\n",
    "#    print(\"Estimated homography : \\n\",  H)\n",
    "\n",
    "    # display images\n",
    "    cv2.imshow(\"object Image\", img1)\n",
    "    cv2.imshow(\"scene with object\", img2)\n",
    "    # cv2.imshow(\"matches\", img_matches)\n",
    "    cv2.imshow(\"resulted detected object\", output)\n",
    "\n",
    "else:\n",
    "    print(\"Error: not enough matches\\n\")\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
